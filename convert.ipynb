{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UNet\n",
    "import mindspore\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import numpy as np\n",
    "from mindspore import Tensor, save_checkpoint,load_checkpoint,Model,load_param_into_net\n",
    "import os\n",
    "import cv2\n",
    "from MyAcc import PixelAcc\n",
    "from mindspore import nn\n",
    "from dataloader import load_train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通过MindSpore的Cell，打印Cell里所有参数的参数名和shape，返回参数字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mindspore_params(network):\n",
    "    \"\"\"Get MindSpore parameter and shape\"\"\"\n",
    "    ms_params = {}\n",
    "    name_set = []\n",
    "    for param in network.get_parameters():\n",
    "        name = param.name\n",
    "        name_set.append(name)\n",
    "        value = param.data.asnumpy()\n",
    "        print(name, value.shape)\n",
    "        ms_params[name] = value\n",
    "    return name_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 对于从hdf5文件导入的模型中，仅保留layer.weights不为空的层，过滤掉无学习参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_from_hdf5_group(f, layers, reshape=False):\n",
    "\n",
    "    filtered_layers = []\n",
    "    for layer in layers:\n",
    "        weights = model.get_layer(layer).get_weights()\n",
    "        if weights:\n",
    "            filtered_layers.append(layer)\n",
    "    return filtered_layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 对卷积权重进行转置\n",
    "MindSpore的卷积层中weight的shape为[out_channel, in_channel, kernel_height, kernel_weight] 而TensorFlow卷积层的weight 的shape为[kernel_height, kernel_weight, in_channel, out_channel] 因此需要进行转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_2_mindspore(h5_model,h5_name_list,ms_name_list, ms_ckpt_path):\n",
    "\n",
    "    new_params_list = []\n",
    "    for i in range (0,len(h5_name_list)):\n",
    "        param_dict = {}\n",
    "        weight,bias  = h5_model.get_layer(h5_name_list[i]).get_weights()\n",
    "        parameter = np.transpose(weight, axes=[3, 2, 0, 1])\n",
    "        param_dict['name'] = ms_name_list[i]\n",
    "        param_dict['data'] = Tensor(parameter)\n",
    "        new_params_list.append(param_dict)\n",
    "    save_checkpoint(new_params_list, os.path.join(ms_ckpt_path, 'hdf2mindspore.ckpt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入模型查看文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('unet.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('unet.hdf5')\t\t\t\t\t#打开h5文件\n",
    "#for key in f.keys():\t\t\t\t\t#查看内部的键\n",
    "#     print(key)\n",
    "#f['model_weights'].attrs.keys()\t\t\t#查看键的属性\n",
    "#f['model_weights'].attrs['layer_names']\t#查看层的名称\n",
    "layer_names = [n.decode('utf8') for n in f['model_weights'].attrs['layer_names']]\n",
    "# print(layer_names)\n",
    "layer_with_weight = load_weights_from_hdf5_group(f,layer_names)\n",
    "for name in layer_with_weight:\n",
    "    print(name)\n",
    "    weight,bias_=model.get_layer(name).get_weights()\n",
    "    print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = UNet()\n",
    "network_param_ms = mindspore_params(network)\n",
    "print(network_param_ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 由于网络名称较多，这里需要手动对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_name_list = ['conv2d_49', 'conv2d_50', 'conv2d_51', 'conv2d_52', 'conv2d_53', 'conv2d_54', 'conv2d_55', 'conv2d_56', 'conv2d_57', 'conv2d_58', 'conv2d_59', 'conv2d_60', 'conv2d_61', 'conv2d_62', 'conv2d_63', 'conv2d_64', 'conv2d_65', 'conv2d_66', 'conv2d_67', 'conv2d_68', 'conv2d_69', 'conv2d_70', 'conv2d_71', 'conv2d_72']\n",
    "mindspore_name_list = ['downsample1.0.weight', 'downsample1.2.weight', 'downsample2.0.weight', 'downsample2.2.weight', 'downsample3.0.weight', 'downsample3.2.weight', 'downsample4.0.weight', 'downsample4.2.weight', 'downsample5.0.weight', 'downsample5.2.weight', 'upconv1.0.weight', 'upsample1.0.weight', 'upsample1.2.weight', 'upconv2.0.weight', 'upsample2.0.weight', 'upsample2.2.weight','upconv3.0.weight', 'upsample3.0.weight', 'upsample3.2.weight', 'upconv4.0.weight', 'upsample4.0.weight', 'upsample4.2.weight', 'outconv.weight', 'sigmoid_conv.0.weight']\n",
    "# print(len(keras_name_list))\n",
    "# print(len(mindspore_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_2_mindspore(model,keras_name_list,mindspore_name_list,'./')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入权重，查看是否正确保存，能否正确导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "param_dict = mindspore.load_checkpoint(\"tf2mindspore.ckpt\",net=network)\n",
    "param_not_load, _ = mindspore.load_param_into_net(network, param_dict)\n",
    "print(param_not_load)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 推理并评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== {'Accuracy': 0.9108557383219401} ==============\n"
     ]
    }
   ],
   "source": [
    "network = UNet()\n",
    "loss_fn = nn.BCELoss()\n",
    "model = Model(network, loss_fn, metrics={\"Accuracy\": PixelAcc()})\n",
    "\n",
    "print(\"============== Starting Testing ==============\")\n",
    "param_dict = load_checkpoint(\"./tf2mindspore.ckpt\")\n",
    "load_param_into_net(network, param_dict)\n",
    "dataset = load_train_data('./train/',512,512,1,shuffle=True)\n",
    "acc = model.eval(dataset)\n",
    "print(\"============== {} ==============\".format(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
